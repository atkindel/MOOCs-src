{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnostic tests for MOOC item response matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data analysis imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "Retrieve list of courses. Define measure names. Read in CSVs for all course-measure pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Data directories-- may need to adjust these\n",
    "home = os.path.expanduser('~')\n",
    "data_dir = home + \"/Code/irt/data/\"\n",
    "course_list_dir = \"done_courses.txt\"\n",
    "\n",
    "# Read in course list\n",
    "courses = []\n",
    "with open(data_dir + course_list_dir) as c_list:\n",
    "    for course in c_list:\n",
    "        courses.append(course.replace('/', '_').rstrip())\n",
    "\n",
    "# Measures computed\n",
    "measures = ['first_view', 'first_attempt', 'last_attempt', 'time_to_first_attempt', 'time_to_last_attempt',\n",
    "            'time_spent_attempting', 'n_attempts', 'first_grade', 'last_grade']\n",
    "\n",
    "# Data-framed CSVs of computed measures\n",
    "data = defaultdict(dict)\n",
    "for course in courses:\n",
    "    for measure in measures:\n",
    "        data[course][measure] = pd.read_csv(data_dir + \"/exports/%s/%s.csv\" % (course, measure), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Earlier problems are viewed more\n",
    "\n",
    "First, we want to sanity check our first_view data against a total ordering of the items.\n",
    "\n",
    "We'd expect to see a relatively smooth (but not necessarily monotonic) decrease in the attempt count as we progress through the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up plots\n",
    "cols = 2\n",
    "fig, axes = plt.subplots(nrows=(len(courses)+1)/cols, ncols=cols)\n",
    "fig.set_figheight(40)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "\n",
    "for idx, course in enumerate(courses):\n",
    "    # Get total number of learners who saw each item and ordering of items in the course\n",
    "    fv = data[course]['first_view']\n",
    "    view_counts = fv.count().sort_values(ascending=False)\n",
    "    item_metadata = pd.read_csv(data_dir + \"/raws/%s_ProblemMetadata.csv\" % course, index_col = 0)\n",
    "    \n",
    "    # Add attempt count to metadata for each item\n",
    "    ncol = {}  # Column for attempt counts\n",
    "    zeros = {}  # Also track unobserved items\n",
    "    for item in item_metadata.index:\n",
    "        iuri = [pid for pid in view_counts.keys() if item in pid]\n",
    "        if not iuri:\n",
    "            zeros[item] = 1\n",
    "            continue\n",
    "        ncol[item] = view_counts[iuri[0]]\n",
    "    item_metadata['view_count'] = pd.Series(ncol, item_metadata.index)\n",
    "    item_metadata['zeros'] = pd.Series(zeros, item_metadata.index)\n",
    "    \n",
    "    # Add numerical rank to metadata for each item\n",
    "    rank = {}\n",
    "    r = 0\n",
    "    for item in item_metadata.index:\n",
    "        rank[item] = r\n",
    "        r += 1\n",
    "    item_metadata['total_order'] = pd.Series(rank, item_metadata.index)\n",
    "    \n",
    "    # Plot item order in course against number of learners who viewed each item or unobserved indicator\n",
    "    ordering = item_metadata['total_order']\n",
    "    views = item_metadata['view_count']\n",
    "    unobserved = item_metadata['zeros']\n",
    "    subp = axes[idx/2,int(idx%2!=0)]\n",
    "    subp.set_title(course)\n",
    "    subp.scatter(x=ordering, y=views, s=14, color='b')\n",
    "    subp.scatter(x=ordering, y=unobserved, s=14, color='r')\n",
    "    xdelt = 5\n",
    "    ydelt = 50\n",
    "    subp.set_xlim(-xdelt, ordering.max()+xdelt)\n",
    "    subp.set_ylim(views.min()-ydelt, views.max()+ydelt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test 2: No negative time deltas\n",
    "\n",
    "The time_to_first_attempt (TTFA) and time_to_last_attempt (TTLA) matrices should not contain any negative numbers.\n",
    "\n",
    "Additionally, the difference between TTLA and TTFA (DIFF) should itself be not negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for course in courses:\n",
    "    print course\n",
    "    \n",
    "    ttfa = data[course]['time_to_first_attempt']\n",
    "    ttfa_neg = ttfa.mask(ttfa >= 0).dropna(how='all')\n",
    "    ttfa_issues = ttfa_neg.count().sum()\n",
    "    print \"\\t TTFA: \" + str(ttfa_issues)\n",
    "    \n",
    "    ttla = data[course]['time_to_last_attempt']\n",
    "    ttla_neg = ttla.mask(ttla >= 0).dropna(how='all')\n",
    "    ttla_issues = ttla_neg.count().sum()\n",
    "    print \"\\t TTLA: \" + str(ttla_issues)\n",
    "    \n",
    "    diff = ttla - ttfa\n",
    "    diff_neg = diff.mask(diff >= 0).dropna(how='all')\n",
    "    diff_issues = diff_neg.count().sum()\n",
    "    print \"\\t DIFF: \" + str(diff_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test 3: Learners take items in order\n",
    "\n",
    "For each course, select a random subsample of learners and plot first_view time against rank order for each item.\n",
    "\n",
    "May not be a clear association in all courses-- ideally some will show as monotonically non-decreasing (that is, up and to the right with some plateaus), and some might show as relatively flat. Especially in a self-paced course, a course with low item count, or any other course where all items might have been released at once, the difference might be hard to see.\n",
    "\n",
    "At minimum, the graphs shouldn't be random or monotonically decreasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up plots\n",
    "cols = 2\n",
    "fig, axes = plt.subplots(nrows=(len(courses)+1)/cols, ncols=cols)\n",
    "fig.set_figheight(40)\n",
    "fig.set_figwidth(20)\n",
    "plt.subplots_adjust(hspace=0.4, wspace=0.2)\n",
    "\n",
    "# Define sample size and rng seed\n",
    "sample_size = 50\n",
    "sample_seed = 0\n",
    "\n",
    "for idx, course in enumerate(courses):\n",
    "    # Derive item rank\n",
    "    item_metadata = pd.read_csv(data_dir + \"/raws/%s_ProblemMetadata.csv\" % course, index_col = 0)\n",
    "    rank = {}\n",
    "    for idxb, item in enumerate(item_metadata.index):\n",
    "        rank[item] = idxb\n",
    "    item_metadata['total_order'] = pd.Series(rank, item_metadata.index)\n",
    "    \n",
    "    # Order view times by item rank\n",
    "    fv_sample = data[course]['first_view'].sample(n=sample_size, random_state=sample_seed)\n",
    "    fv_sample.rename(columns=lambda x: rank[x[-36:-4]], inplace=True)\n",
    "    fv_sample.sort_index(axis=1, inplace=True)\n",
    "    \n",
    "    # Plot each learner\n",
    "    for i in range(sample_size):\n",
    "        row = fv_sample.iloc[i]\n",
    "        row.plot(ax=axes[idx/2,int(idx%2!=0)])\n",
    "        axes[idx/2,int(idx%2==0)].set_title(course)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
